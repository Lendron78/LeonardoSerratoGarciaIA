{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a28ad3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv \n",
    "import numpy as np \n",
    "import os\n",
    "\n",
    "dataSet = 'Desktop\\\\9no Semestre\\\\IA\\\\img\\\\Emociones'\n",
    "faces  = os.listdir(dataSet)\n",
    "print(faces)\n",
    "\n",
    "labels = []\n",
    "facesData = []\n",
    "label = 0 \n",
    "for face in faces:\n",
    "    facePath = dataSet+'/'+face\n",
    "    for faceName in os.listdir(facePath):\n",
    "        labels.append(label)\n",
    "        facesData.append(cv.imread(facePath+'/'+faceName,0))\n",
    "    label = label + 1\n",
    "    \n",
    "#print(np.count_nonzero(np.array(labels)==0)) \n",
    "faceRecognizer = cv.face.LBPHFaceRecognizer_create()\n",
    "faceRecognizer.train(facesData, np.array(labels))\n",
    "faceRecognizer.write('imgLBPHFace.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793dabe0",
   "metadata": {},
   "source": [
    "# Librerias \n",
    "Primero, se importan las bibliotecas necesarias: OpenCV (cv2) para el procesamiento de imágenes y numpy para el manejo de matrices. También se importa la biblioteca os para la manipulación de archivos y directorios.\n",
    "\n",
    "# Rutas\n",
    "Se define una ruta donde se almacenan las imágenes del conjunto de datos, organizadas en carpetas por emociones, el código recorre cada carpeta de emociones y, dentro de cada carpeta, recorre cada archivo de imagen, agregando la etiqueta correspondiente y los datos de la imagen a las listas respectivas. La etiqueta asignada corresponde a la carpeta de la emoción a la que pertenece la imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155fe0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import os \n",
    "\n",
    "faceRecognizer = cv.face.LBPHFaceRecognizer_create()\n",
    "faceRecognizer.read('imgLBPHFace.xml')\n",
    "\n",
    "cap = cv.VideoCapture(0)\n",
    "rostro = cv.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if ret == False: \n",
    "        break\n",
    "    # Voltear el frame horizontalmente para modo espejo\n",
    "    frame = cv.flip(frame, 1)\n",
    "    \n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    cpGray = gray.copy()\n",
    "    rostros = rostro.detectMultiScale(gray, 1.3, 3)\n",
    "    for (x, y, w, h) in rostros:\n",
    "        frame2 = cpGray[y:y+h, x:x+w]\n",
    "        frame2 = cv.resize(frame2, (100, 100), interpolation=cv.INTER_CUBIC)\n",
    "        result = faceRecognizer.predict(frame2)\n",
    "        \n",
    "        if result[1] < 2800:\n",
    "            cv.putText(frame, '{}'.format(faces[result[0]]), (x, y-25), 2, 1.1, (0, 255, 0), 1, cv.LINE_AA)\n",
    "            cv.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        \n",
    "    cv.imshow('frame', frame)\n",
    "    k = cv.waitKey(1)\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e403f721",
   "metadata": {},
   "source": [
    "Se crea un objeto LBPHFaceRecognizer y se carga un modelo entrenado desde un archivo XML. Luego, se inicia la captura de video desde la cámara web y se carga un clasificador en cascada para la detección de rostros.\n",
    "\n",
    "En un bucle continuo, se lee cada cuadro del video y se procesa para la detección y reconocimiento de rostros. Los pasos específicos incluyen:\n",
    "\n",
    "- Leer un cuadro del video y verificar si la lectura fue exitosa.\n",
    "- Voltear el cuadro horizontalmente para un efecto de espejo.\n",
    "- Convertir el cuadro a escala de grises.\n",
    "- Detectar rostros en el cuadro en escala de grises.\n",
    "- Para cada rostro detectado, extraer la región de interés y redimensionarla.\n",
    "- Utilizar el modelo de reconocimiento facial para predecir la emoción o identidad del rostro.\n",
    "- Si la predicción tiene una confianza suficientemente alta, se dibuja un rectángulo alrededor del rostro detectado y se        muestra la etiqueta correspondiente.\n",
    "- Mostrar el cuadro procesado en una ventana.\n",
    "- Terminar el bucle si se presiona la tecla 'Esc'.\n",
    "- Finalmente, se liberan los recursos de la cámara y se cierran todas las ventanas de OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58eaa970",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24bfa01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
